---
title: "Caso Pŕactico Final Evaluable"
output:
  pdf_document: default
  html_notebook: default
  html_document: default
---

Tomaremos el dataset Salaries.csv

El conjunto de datos consiste en los salarios de nueve meses recogidos de 397 profesores universitarios en los EE.UU. durante 2008 y 2009. Además de los salarios, también se recogió el rango del profesor, el sexo, la disciplina, los años desde el doctorado y los años de servicio. Así, hay un total de 6 variables, que se describen a continuación.

      1. rank: Categórica - de profesor asistente, profesor asociado o catedrático
      2. discipline: Categórica - Tipo de departamento en el que trabaja el profesor, ya sea aplicado (B) o teórico (A)
      3. yrs.since.phd: Continuo - Número de años desde que el profesor obtuvo su doctorado
      4. yrs.service: Continuo - Número de años que el profesor ha prestado servicio al departamento y/o a la universidad
      5. sex: Categórico - Sexo del profesor, hombre o mujer
      6. salary: Continuo - Sueldo de nueve meses del profesor (USD)

El objetivo de esta práctica consiste en realizar un estudio íntegro del dataset para terminar implementando un modelo lineal regularizado que realice predicciones sobre el salario a percibir de un profesor. Asimismo, se pedirá aprovechar la explicabilidad de estos modelos y los estudios estadísticos realizados para arrojar intuiciones y dependencias en los datos.

Para ello, se pide al estudiante que realice los siguientes pasos:

1. Carga los datos. Realiza una inspección por variables de la distribución de salarios en función de cada atributo visualmente. Realiza las observaciones pertinentes. ¿Qué variables son mejores para separar los datos?

```{r}
df <- read.csv('Salaries.csv', na.strings = "?")
str(df)
```
```{r}
dim(df)
```

```{r}
head(df)
```
Todas las variables categóricas las pasamos a factores y eliminamos la columna X ya que no .

```{r}
df$rank <- as.factor(df$rank)
df$sex <- as.factor(df$sex)
df$discipline <- as.factor(df$discipline)
```

Comprobamos que las variables han sido formateadas correctamente:

```{r}
str(df)
```
```{r}
summary(df)
```

```{r}
df$X <- NULL # Eliminamos la columna X porque no tiene interés para nuestro análisis
df
```

```{r}
summary(df)
```
Realizamos una inspección por variables de la distribución de salarios en función de cada atributo visualmente. Para ello, cargamos la librería ggplot.

```{r}
library(ggplot2)

ggplot(data=df, aes(x=salary, fill=rank) ) +
    geom_histogram(alpha = 0.5, position="identity", bins = 30)
```
Como era de esperar, existe una tendencia a tener mayor salario si tienes un rango superior.

```{r}
ggplot(data=df, aes(x=salary, fill=discipline) ) +
    geom_histogram(alpha = 0.5, position="identity", bins = 30)
```
De este gráfico extraemos la conclusión de que la disciplina del profesor no impacta en el salario.

```{r}
ggplot(df, aes(x = yrs.since.phd, y = salary)) +
  geom_point(shape=1) +
  geom_smooth(method=lm, level=0.99)
```

```{r}
ggplot(df, aes(x = yrs.service, y = salary)) +
  geom_point(shape=1) +
  geom_smooth(method=lm, level=0.99)
```
Existe una tendencia a tener un mayor salario en función de los años de servicio y de los años que han pasado desde el PhD.

```{r}
ggplot(data=df, aes(x=salary, fill=sex) ) +
    geom_histogram(alpha = 0.5, position="identity", bins = 30)
```
```{r}
library(dplyr)

datos_mujeres <- df %>% filter(sex == 'Female')
salario_maximo_mujeres <- max(datos_mujeres$salary)

cat("El salario máximo de las mujeres es:", salario_maximo_mujeres, "\n")
```

Es de destacar que hay mucha menor cantidad de mujeres que de hombres. Además, el máximo salario adquirido por una mujer no supera los 165000 dolares.

2. ¿Podemos emplear un test paramétrico para determinar si las medias de salarios entre hombres y mujeres son las mismas o difieren? Ten en cuenta que, en tanto que se pide usar un test paramétrico, se deberá determinar si las muestras cumplen con las hipótesis necesarias.

Podemos emplear un test paramétrico, como la prueba t de Student, para determinar si las medias de salarios entre hombres y mujeres son las mismas o difieren. Sin embargo, antes de aplicar la prueba t, es importante verificar si los datos cumplen con las hipótesis necesarias para este tipo de prueba. La principal hipótesis para la prueba t es:

Normalidad: Los datos deben provenir de una distribución normal. Podemos utilizar métodos gráficos, como un gráfico Q-Q (quantile-quantile), o pruebas estadísticas, como la prueba de normalidad de Shapiro-Wilk.

```{r}
# Verificamos la normalidad con gráfico Q-Q
ggplot(df, aes(sample = salary, color = sex)) +
  geom_qq() +
  ggtitle("Gráfico Q-Q de Salarios por Género")
```

```{r}
# Prueba de normalidad de Shapiro-Wilk
shapiro_test_hombres <- shapiro.test(df$salary[df$sex == "Male"])
shapiro_test_mujeres <- shapiro.test(df$salary[df$sex == "Female"])
```

```{r}
# Imprimir resultados
cat("Prueba de Shapiro-Wilk para hombres:", shapiro_test_hombres$p.value, "\n")
```

```{r}
cat("Prueba de Shapiro-Wilk para mujeres:", shapiro_test_mujeres$p.value, "\n")
```

En este casos los p-valores son mayores que 0.05 por lo tanto aceptamos las correspondientes hipótesis nulas H0, es decir, que las muestras provienen de una población con una distribución que se puede aproximar por una normal.

```{r}
# Realizamos el test t-student
t_test_result <- t.test(salary ~ sex, data = df)
cat("Prueba t de Student para comparar medias de salarios entre hombres y mujeres:\n")
print(t_test_result)
```
La hipótesis nula (H0) en este caso sería que no hay diferencia significativa en las medias salariales entre hombres y mujeres. La hipótesis alternativa (H1) sería que hay una diferencia significativa. Dado que el valor p (0.002664) es menor que el nivel de significancia comúnmente utilizado de 0.05, hay evidencia suficiente para rechazar la hipótesis nula.

La conclusión es que hay una diferencia significativa en las medias salariales entre hombres y mujeres. Además, la estimación de la diferencia entre las medias es de aproximadamente \$10,088.0, con un intervalo de confianza del 95% que va desde -\$23,037.92 a -$5,138.10. Esto sugiere que, en promedio, los hombres ganan más que las mujeres en este conjunto de datos.

3. Divide el dataset tomando las primeras 317 instancias como train y las últimas 80 como test. Entrena un modelo de regresión lineal con regularización Ridge y Lasso en train seleccionando el que mejor **MSE** tenga. Da las métricas en test. Valora el uso del One Hot Encoder, en caso de emplearlo arguméntalo.

Contamos valores faltantes:

```{r}
sapply(df, function(x) sum(is.na(x)))
```

Observamos que no hay. Realizamos un One Hot Encoding sobre la variable sex. Cuando tienes variables categóricas en tu conjunto de datos (por ejemplo, variables que representan el género, el país, el tipo de producto, etc.), muchos algoritmos de aprendizaje automático requieren que estas variables sean convertidas a una forma numérica. El One-Hot Encoding es una manera efectiva de realizar esta conversión. El One-Hot Encoding preserva la información de las categorías originales al convertirlas en columnas binarias separadas. Cada categoría se representa como una columna y se asigna un valor de 0 o 1, dependiendo de si la observación pertenece o no a esa categoría. 

```{r}
dfOHE <- model.matrix(~., df)
head(dfOHE)
```

Dividimos el dataset

```{r}
X <- data.matrix(dfOHE)
dim(X)
```

Pasamos un modelo Ridge y otro Lasso viendo rendimientos, para ello primero creamos la separación X_train/y_train y X_test/y_test

```{r}
X_train <- X[1:317,]
y_train <- y[1:317]
X_test <- X[318:397,]
y_test <- y[318:397]
```

Aplicamos Ridge

```{r}
library(glmnet)
```


```{r}
set.seed(42)
cv.ridge <- cv.glmnet(X_train, y_train, family='gaussian', alpha=0, type.measure='mse')
# Resultados
plot(cv.ridge)
```


```{r}
# Este es el mejor valor de lambda
cv.ridge$lambda.min
```

```{r}
# Este es el valor del error que se estima para ese valor lambda mínimo dado en MSE
min(cv.ridge$cvm)
```

Observamos que el modelo regularizado de Ridge con λ óptimo cuenta con MSE de 11353212.
Aplicamos Lasso. Para ejecutar un modelo hueco de Lasso sólo tenemos que cambiar Alpha=0 en la función glmnet y aplicarla igual que en el caso Ridge

```{r}
set.seed(42)
cv.lasso <- cv.glmnet(X_train, y_train, family='gaussian', alpha=1, type.measure='mse')
# Resultados
plot(cv.lasso)
```
```{r}
# Este es el mejor valor de lambda
cv.lasso$lambda.min
```

```{r}
# Este es el valor del error que se estima para ese valor lambda mínimo dado en MSE
min(cv.lasso$cvm)
```

Observamos que el modelo regularizado de Lasso con λ óptimo cuenta con MSE de 778836.5. Como el MSE del modelo de Lasso es menor al de Ridge, nos quedamos con el modelo obtenido por la regularización de Lasso. Veamos los coeficientes del módelo óptimo obtenido por la regularizaicón de Lasso.

```{r}
coef(cv.lasso, s=cv.lasso$lambda.min)
```
Calculamos la predicción en test y sus métricas. Mostramos las predicciones y los correspondientes valores reales.

```{r}
predict.glmnet(cv.lasso$glmnet.fit, newx=X_test, s=cv.lasso$lambda.min)
```

4. Estudia la normalidad de los residuos del modelo resultante, ¿detectas algún sesgo?

```{r}
residuos_modelo <- residuals(y_pred)


qq_plot <- ggplot(data.frame(residuos_modelo), aes(sample = residuos_modelo)) +
  geom_qq() +
  geom_qq_line() +
  ggtitle("Q-Q Plot de los Residuos")
```


5. ¿Qué conclusiones extraes de este estudio y del modelo implementado? ¿Consideras correcto el rendimiento del mismo?

¡Mucho ánimo y espero que disfrutéis de esta última práctica!


